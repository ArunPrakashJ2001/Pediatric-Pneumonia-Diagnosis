{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8s5ZQc4uuJnd"
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "import numpy as np\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-usV_7wuJp2"
   },
   "outputs": [],
   "source": [
    "directory='/content/Pediatric Chest X-ray Pneumonia'\n",
    "train_directory=os.path.join(directory,'train')\n",
    "test_directory=os.path.join(directory,'test')\n",
    "val_directory=os.path.join(directory,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1/255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 32 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory( train_directory, \n",
    "        classes = ['NORMAL', 'PNEUMONIA'],\n",
    "        target_size=(224, 224),  \n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 32 using valid_datagen generator\n",
    "validation_generator = validation_datagen.flow_from_directory( val_directory,\n",
    "        classes = ['NORMAL', 'PNEUMONIA'],\n",
    "        target_size=(224, 224), \n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory( test_directory,\n",
    "        classes = ['NORMAL', 'PNEUMONIA'],\n",
    "        target_size=(224, 224), \n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VAL=validation_generator.n//validation_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "print(\"STEP_SIZE_TRAIN: \",STEP_SIZE_TRAIN)\n",
    "print(\"STEP_SIZE_TEST: \",STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model= tf.keras.applications.Xception(include_top = False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2F26Q7yluBe1"
   },
   "outputs": [],
   "source": [
    "def residual_unit(residual_input_data, filters):\n",
    "    identity_x = residual_input_data\n",
    "    \n",
    "    filter1,filter2,filter3 = filters\n",
    "    \n",
    "    conv_op_1 = tf.keras.layers.Conv2D(filters=filter1,\n",
    "                      kernel_size=(1,1),\n",
    "                      strides=(1,1),\n",
    "                      dilation_rate = 1,\n",
    "                      padding='same')(residual_input_data)\n",
    "    \n",
    "    batch_norm_op_2 = tf.keras.layers.BatchNormalization()(conv_op_1)\n",
    "    activation_op_2 = Activation('relu')(batch_norm_op_2)\n",
    "    conv_op_2 = tf.keras.layers.Conv2D(filters=filter2,\n",
    "                      kernel_size=(3,3),\n",
    "                      strides=(1,1),\n",
    "                      dilation_rate = 1,\n",
    "                      padding='same')(activation_op_2)\n",
    "\n",
    "    batch_norm_op_3 = tf.keras.layers.BatchNormalization()(conv_op_2)\n",
    "    activation_op_3 = Activation('relu')(batch_norm_op_3)\n",
    "    conv_op_3 = tf.keras.layers.Conv2D(filters=filter3,\n",
    "                      kernel_size=(1,1),\n",
    "                      strides=(1,1),\n",
    "                      dilation_rate = 1,\n",
    "                      padding='same')(activation_op_3)\n",
    "    \n",
    "    batch_norm_op_4 = tf.keras.layers.BatchNormalization()(conv_op_3)\n",
    "    \n",
    "    if identity_x.shape[-1] != conv_op_3.shape[-1]:\n",
    "        filter_n = conv_op_3.shape[-1]\n",
    "        \n",
    "        identity_x = tf.keras.layers.Conv2D(filters=filter_n,\n",
    "                          kernel_size=(1,1),\n",
    "                          strides=(1,1),\n",
    "                          dilation_rate=1,\n",
    "                          padding='same')(identity_x)\n",
    "\n",
    "\n",
    "        identity_x = tf.keras.layers.BatchNormalization()(identity_x)\n",
    "        \n",
    "    output = tf.keras.layers.Add()([identity_x, batch_norm_op_4])\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_module(attention_input_data, filters,p=1):\n",
    "    p_res_unit_op_1 = attention_input_data\n",
    "    for _ in range(p):\n",
    "        p_res_unit_op_1 = residual_unit(p_res_unit_op_1, filters=filters)\n",
    "\n",
    "    #print(\"pres\", p_res_unit_op_1.shape)\n",
    "\n",
    "    trunk_branch_op = trunk_branch(trunk_input_data=p_res_unit_op_1, filters=filters)\n",
    "\n",
    "    #print(\"trunk_branch_op\", trunk_branch_op.shape)\n",
    "\n",
    "    mask_branch_op = mask_branch(mask_input_data=p_res_unit_op_1, filters=filters)\n",
    "\n",
    "    print(\"mask_branch_op\", mask_branch_op.shape)\n",
    "\n",
    "    ar_learning_op = attention_residual_learning(mask_input=mask_branch_op, trunk_input=trunk_branch_op)\n",
    "    print(\"ar_learning_op\", ar_learning_op.shape)\n",
    "\n",
    "    p_res_unit_op_2 = ar_learning_op\n",
    "    for _ in range(p):\n",
    "        p_res_unit_op_2 = residual_unit(p_res_unit_op_2, filters=filters)\n",
    "    print(\"pres2\", p_res_unit_op_2.shape)\n",
    "    return p_res_unit_op_2\n",
    "\n",
    "def trunk_branch(trunk_input_data, filters,t=2):\n",
    "    \n",
    "    t_res_unit_op = trunk_input_data\n",
    "    for _ in range(t):\n",
    "        t_res_unit_op = residual_unit(t_res_unit_op, filters=filters)\n",
    "\n",
    "    return t_res_unit_op\n",
    "\n",
    "def mask_branch(mask_input_data, filters, m=1,r=1):\n",
    "    \n",
    "    print(mask_input_data.shape)\n",
    "\n",
    "    downsampling = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \n",
    "                                  strides=(2, 2),\n",
    "                                  padding='same')(mask_input_data)\n",
    "    print('down', downsampling.shape)\n",
    "    for _ in range(m):\n",
    "        for j in range(r):\n",
    "            downsampling = residual_unit(residual_input_data=downsampling, filters=filters)\n",
    "\n",
    "        downsampling = tf.keras.layers.MaxPool2D(pool_size=(2, 2), \n",
    "                                      strides=(2, 2),\n",
    "                                      padding='same')(downsampling)\n",
    "        print(downsampling.shape)\n",
    "    #===================================================================================================\n",
    "\n",
    "    middleware = downsampling\n",
    "    for _ in range(2 *r):\n",
    "        middleware = residual_unit(residual_input_data=middleware, filters=filters)\n",
    "\n",
    "    #===================================================================================================\n",
    "\n",
    "    upsampling = tf.keras.layers.UpSampling2D(size=(2, 2))(middleware)\n",
    "\n",
    "\n",
    "    for _ in range(m):\n",
    "        for j in range(r):\n",
    "            upsampling = residual_unit(residual_input_data=upsampling, filters=filters)\n",
    "\n",
    "        upsampling = tf.keras.layers.UpSampling2D(size=(2, 2))(upsampling)\n",
    "   # print(upsampling.shape)\n",
    "\n",
    "    #resized_images= tf.image.resize(upsampling, tf.constant([mask_input_data.shape[1], mask_input_data.shape[2]])) \n",
    "    \n",
    "    #print(resized_images.shape)\n",
    "\n",
    "    conv_filter = upsampling.shape[-1]\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(filters=conv_filter,\n",
    "                      kernel_size=(1,1),\n",
    "                      strides=(1,1),\n",
    "                      dilation_rate=1,\n",
    "                      padding='same')(upsampling)\n",
    "    \n",
    "    conv2 = tf.keras.layers.Conv2D(filters=conv_filter,\n",
    "                      kernel_size=(1,1),\n",
    "                      strides=(1,1),\n",
    "                      dilation_rate=1,\n",
    "                      padding='same')(conv1)\n",
    "\n",
    "    sigmoid = Activation('sigmoid')(conv2)\n",
    "\n",
    "    return sigmoid\n",
    "\n",
    "def attention_residual_learning(mask_input, trunk_input):\n",
    "    Mx = tf.keras.layers.Lambda(lambda x: 1 + x)(mask_input) # 1 + mask\n",
    "    print(\"Mx:\", Mx.shape) # (None, 56, 56, 256)\n",
    "    print(\"trunk_input:\", trunk_input.shape) # (None, 55, 55, 256)\n",
    "\n",
    "    \n",
    "    mask_dim = Mx.shape[1]\n",
    "    trunk_dim = trunk_input.shape[1]\n",
    "\n",
    "    print(\"Mask:\", mask_dim)\n",
    "    print(\"Trunk:\", trunk_dim)\n",
    "\n",
    "    # If dimensions do not match, then perform reshaping ...\n",
    "    if (mask_dim > trunk_dim):\n",
    "        diff = mask_dim - trunk_dim\n",
    "        n_pair_pads = np.floor(diff/2)\n",
    "        n_single_pads = diff % 2\n",
    "        \n",
    "        #print(\"trunk_input[0]\", trunk_input[0].shape) # (55, 55, 256)\n",
    "        #print(type(trunk_input[0])) # <class 'keras.engine.keras_tensor.KerasTensor'> \n",
    "\n",
    "        # ZeroPadding()'s arguments have to be integers or tuple(s) of integers \n",
    "        n_pair_pads = int(n_pair_pads)\n",
    "        n_single_pads = int(n_single_pads)\n",
    "\n",
    "        x = tf.reshape(trunk_input[0], (1,) + trunk_input.shape[1:])\n",
    "\n",
    "        # Same padding on top, bottom, left & right ...\n",
    "        x = tf.keras.layers.ZeroPadding2D( padding = n_pair_pads )(x)\n",
    "\n",
    "        # Specifying padding in the manner ((top,bottom), (left,right)) ...\n",
    "        x = tf.keras.layers.ZeroPadding2D( padding = ((0,n_single_pads),(0,n_single_pads))\n",
    "                                        ) (x)\n",
    "                                        \n",
    "        # Converting from (1,x1,x2,x3) to (x1,x2,x3) ... \n",
    "        trunk_input = x\n",
    "\n",
    "    elif (trunk_dim > mask_dim):\n",
    "        diff = trunk_dim - mask_dim # 14-13=1\n",
    "        n_pair_pads = np.floor(diff/2) # 1/2 = 0\n",
    "        n_single_pads = diff % 2 # 1%2 = 1\n",
    "        \n",
    "        # ZeroPadding()'s arguments have to be integers or tuple(s) of integers \n",
    "        n_pair_pads = int(n_pair_pads)\n",
    "        n_single_pads = int(n_single_pads)\n",
    "\n",
    "        x = tf.reshape(Mx[0], (1,) + Mx.shape[1:])\n",
    "\n",
    "        # Same padding on top, bottom, left & right ...\n",
    "        x = tf.keras.layers.ZeroPadding2D( padding = n_pair_pads )(x)\n",
    "\n",
    "        # Specifying padding in the manner ((top,bottom), (left,right)) ...\n",
    "        x = tf.keras.layers.ZeroPadding2D( padding = ((0,n_single_pads),(0,n_single_pads))\n",
    "                                        ) (x)\n",
    "                                        \n",
    "        # Converting from (1,x1,x2,x3) to (x1,x2,x3) ... \n",
    "        Mx = x\n",
    "\n",
    "    print(\"Mx after zp:\", Mx.shape)\n",
    "    print(\"trunk_input after zp:\", trunk_input.shape)   \n",
    "\n",
    "    return tf.keras.layers.Multiply()([Mx, trunk_input]) # M(x) * T(x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'block13_sepconv2_act'   \n",
    "layer_output = base_model.get_layer(layer_name).output\n",
    "new_base_model = keras.Model(base_model.input, layer_output)\n",
    "\n",
    "input1 = layer_output\n",
    "att_mod_1 = attention_module(new_base_model.output, filters=[728,728,1024]) # 32, 64, 128\n",
    "print('att_mod_1', att_mod_1.shape)\n",
    "\n",
    "avg_pool_layer = tf.keras.layers.GlobalAveragePooling2D()(att_mod_1)\n",
    "fc1 = tf.keras.layers.Dense(512, activation = 'relu')(avg_pool_layer)\n",
    "dp = tf.keras.layers.Dropout(0.2)(fc1)\n",
    "fully_connected_layer_last = Dense(1, activation='sigmoid')(dp)\n",
    "\n",
    "pre = Model(inputs=input1, outputs=fully_connected_layer_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZQSjBisvlOh"
   },
   "outputs": [],
   "source": [
    "final_model = pre(layer_output) \n",
    "pipe_model = Model(base_model.input, final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kms37StjvuK5",
    "outputId": "0e3da6f5-839f-43c0-a0e0-81c9a2fc74af"
   },
   "outputs": [],
   "source": [
    "pipe_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = pipe_model.fit(train_generator,\n",
    "steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "epochs=30,\n",
    "class_weight= {0:1.939,1:0.674},\n",
    "verbose=1,\n",
    "validation_data = validation_generator,\n",
    "validation_steps=STEP_SIZE_VAL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xx.predict(test_generator,verbose=1)\n",
    "final_preds=[]\n",
    "for i in preds:\n",
    "    if(i >= 0.5):\n",
    "        final_preds.append(1)\n",
    "    else:\n",
    "        final_preds.append(0)\n",
    "accuracy = accuracy_score(list(test_generator.classes), final_preds)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(list(test_generator.classes), final_preds)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(list(test_generator.classes), final_preds)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(list(test_generator.classes), final_preds)\n",
    "print('F1 score: %f' % f1)\n",
    "fpr, tpr, _ = roc_curve(test_generator.classes, final_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "pr, tpr, _ = roc_curve(test_generator.classes, final_preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7vMvCBC-TM3"
   },
   "outputs": [],
   "source": [
    "pipe_model.save(\"/content/drive/MyDrive/xception_ran.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'],marker = 'v')\n",
    "plt.plot(history.history['val_accuracy'],marker = '*')\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'],marker = 'v')\n",
    "plt.plot(history.history['val_loss'],marker = '*')\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XFPI1uEeDiC"
   },
   "outputs": [],
   "source": [
    "xception_ran = keras.models.load_model('/content/drive/MyDrive/xception_ran.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory='/content/Pediatric Chest X-ray Pneumonia'\n",
    "train_directory=os.path.join(directory,'train')\n",
    "test_directory=os.path.join(directory,'test')\n",
    "val_directory=os.path.join(directory,'val')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( train_directory, \n",
    "        classes = ['NORMAL', 'PNEUMONIA'],\n",
    "        target_size=(224, 224),  \n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory( val_directory,\n",
    "        classes = ['NORMAL', 'PNEUMONIA'],\n",
    "        target_size=(224,224), \n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory( test_directory,\n",
    "        classes = ['NORMAL', 'PNEUMONIA'],\n",
    "        target_size=(224, 224), \n",
    "        batch_size=1,\n",
    "        class_mode='binary',\n",
    "        shuffle=False)\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VAL=validation_generator.n//validation_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "print(\"STEP_SIZE_TRAIN: \",STEP_SIZE_TRAIN)\n",
    "print(\"STEP_SIZE_TEST: \",STEP_SIZE_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx = tf.keras.models.load_model('/content/drive/MyDrive/xception_ran.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx.get_layer(name = 'model_1').summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_layer1 = tf.keras.models.Model(\n",
    "    inputs=modelx.inputs,\n",
    "    outputs=modelx.get_layer(name = 'block13_sepconv2_act').output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHWK4TCYmBEQ"
   },
   "outputs": [],
   "source": [
    "f1train = features_layer1.predict(train_generator,verbose=1)\n",
    "f1test = features_layer1.predict(test_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHHAmhzsln9_"
   },
   "outputs": [],
   "source": [
    "features_layer2 = tf.keras.models.Model(\n",
    "    inputs=modelx.get_layer('model_1').input,\n",
    "    outputs=modelx.get_layer(name = 'model_1').get_layer(name = 'dense').output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2train = features_layer2.predict(f1train,verbose=1)\n",
    "f2test = features_layer2.predict(f1test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_generator.classes\n",
    "test_labels = test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(f2test)\n",
    "df = pd.DataFrame()\n",
    "df[\"y\"] = test_labels\n",
    "df[\"Component-1\"] = tsne_results[:,0]\n",
    "df[\"Component-2\"] = tsne_results[:,1]\n",
    "category_to_label = {0: 'Normal', 1:'Pneumonia'}\n",
    "\n",
    "#plt.figure(figsize=(16,9))\n",
    "sns.scatterplot(x=\"Component-1\", y=\"Component-2\" ,legend=\"full\",alpha=1, hue= map(lambda x: \"Normal\" if x == 0 else \"Pneumonia\", df.y.tolist()),palette=sns.color_palette(\"hls\", 2), data=df).set(title=\"Pediatric Pneumonia Test data T-SNE projection\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
